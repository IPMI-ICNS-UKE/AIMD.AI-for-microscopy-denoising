{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe813e1-2098-43cd-9837-00a31742ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e281c767-2f3b-41a7-8975-fde76da38b9a",
   "metadata": {},
   "source": [
    "## Training data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6021d1-da7a-4087-a2b0-d3a57d94dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder path for FMD rawdata\n",
    "path = pathlib.Path(os.getcwd())\n",
    "FMD_rawdata = path/'FMD_rawdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e247053-691d-499b-a075-cbdaef2bbaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have the required permissions to read/write in the directories you specify when using this function\n",
    "def unpack_FMD_zip(parent_zip_path, extract_to):\n",
    "    #Unpacks multiple zip files from a parent zip file.\n",
    "    \n",
    "    # Make sure the destination directory exists\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "    \n",
    "    with zipfile.ZipFile(parent_zip_path, 'r') as parent_zip:\n",
    "        # Extract all zip files from the parent zip file\n",
    "        for file in parent_zip.namelist():\n",
    "            if file.endswith('.tar'):\n",
    "                parent_zip.extract(file, extract_to)\n",
    "                tarfile_path = os.path.join(extract_to,file)\n",
    "                # Now extract the zip file just extracted\n",
    "                with tarfile.open(tarfile_path, 'r') as tar_ref:\n",
    "                    tar_ref.extractall(extract_to)\n",
    "                # Optionally delete the inner zip file after extraction\n",
    "                os.remove(os.path.join(extract_to, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf90aaa-0a29-4b04-9152-9d11920a15dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpack_FMD_zip(FMD_rawdata/'24744648.zip',FMD_rawdata) #24744648 is the zip file name of the FMD dataset when downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d1c3fb-417c-4800-9c1c-5e63ab3d7db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove # from the line below to delete the original zip file of the FMD dataset\n",
    "# os.remove(FMD_rawdata/'24744648.zip')# rename folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d91b442-de40-4362-ac83-2d9f4664babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the test folder to fit repository data structure\n",
    "os.rename(FMD_rawdata/'test_mix',FMD_rawdata/'FMD_testmix')\n",
    "# move testfolder to fit repository data structure\n",
    "shutil.move(FMD_rawdata/'FMD_testmix',path)\n",
    "# update path\n",
    "FMD_testmix = path/'FMD_testmix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02822706-f63a-46a3-8115-2d35284192e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataType = ['avg2','avg4','avg8','avg16','raw','gt']\n",
    "Sample = ['Confocal_BPAE_B', 'Confocal_BPAE_G', 'Confocal_BPAE_R','Confocal_FISH','Confocal_MICE',\n",
    "         'TwoPhoton_BPAE_B', 'TwoPhoton_BPAE_G', 'TwoPhoton_BPAE_R', 'TwoPhoton_MICE',\n",
    "         'WideField_BPAE_B', 'WideField_BPAE_G', 'WideField_BPAE_R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f4bfd-e42e-4a67-a422-cc9f398acbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = np.zeros((6,512,512,50)) # allocate space to load all DataTypes of a Sample\n",
    "\n",
    "for i in Sample:\n",
    "    base = os.path.join(FMD_rawdata,i)\n",
    "    for j in range(1,21):                # number of FOVs acquired per sample\n",
    "        files_avg2 = sorted(os.listdir(os.path.join(base, DataType[0],str(j)))) # avg2 directory\n",
    "        files_avg4 = sorted(os.listdir(os.path.join(base, DataType[1],str(j)))) # avg4 directory\n",
    "        files_avg8 = sorted(os.listdir(os.path.join(base, DataType[2],str(j)))) # avg8 directory\n",
    "        files_avg16 = sorted(os.listdir(os.path.join(base, DataType[3],str(j)))) # avg16 directory\n",
    "        files_avg1 = sorted(os.listdir(os.path.join(base, DataType[4],str(j)))) # raw directory\n",
    "        files_gt = sorted(os.listdir(os.path.join(base, DataType[5],str(j)))) # gt directory\n",
    "\n",
    "        for k in range(50):              # number of images acquired per sample per FOV\n",
    "            if k < len(files_avg2):\n",
    "                scaled[0, :, :, k] = cv2.imread(os.path.join(base, DataType[0], str(j), files_avg2[k]),cv2.IMREAD_GRAYSCALE)  # avg2\n",
    "            if k < len(files_avg4):\n",
    "                scaled[1, :, :, k] = cv2.imread(os.path.join(base, DataType[1], str(j), files_avg4[k]),cv2.IMREAD_GRAYSCALE)  # avg4\n",
    "            if k < len(files_avg8):\n",
    "                scaled[2, :, :, k] = cv2.imread(os.path.join(base, DataType[2], str(j), files_avg8[k]),cv2.IMREAD_GRAYSCALE)  # avg8\n",
    "            if k < len(files_avg16):\n",
    "                scaled[3, :, :, k] = cv2.imread(os.path.join(base, DataType[3], str(j), files_avg16[k]),cv2.IMREAD_GRAYSCALE)  # avg16\n",
    "            if k < len(files_avg1):\n",
    "                scaled[4, :, :, k] = cv2.imread(os.path.join(base, DataType[4], str(j), files_avg1[k]),cv2.IMREAD_GRAYSCALE)  # raw\n",
    "            if len(files_gt) > 0:\n",
    "                scaled[5, :, :, k] = cv2.imread(os.path.join(base, DataType[5], str(j), files_gt[0]),cv2.IMREAD_GRAYSCALE)  # gt / avg50\n",
    "\n",
    "        # Create directories for saved images\n",
    "        noisy_dir = os.path.join(path, 'FMD_noisy')\n",
    "        if not os.path.exists(noisy_dir):\n",
    "            os.makedirs(noisy_dir)\n",
    "            \n",
    "        gt_dir = os.path.join(path, 'FMD_GT')\n",
    "        if not os.path.exists(gt_dir):\n",
    "            os.makedirs(gt_dir)\n",
    "\n",
    "        # save images in respective directories\n",
    "        for l in range(5):             \n",
    "            for k in range(50):\n",
    "                filename = f\"{i}_{DataType[l]}_FOV{j}_{k + 1}.png\"\n",
    "                cv2.imwrite(os.path.join(noisy_dir, filename), scaled[l, :, :, k]) # avg1, avg2, avg4, avg8, avg16\n",
    "                cv2.imwrite(os.path.join(gt_dir, filename), scaled[5, :, :, k]) # corresponding ground truth pngs\n",
    "        \n",
    "        # clear scaled\n",
    "        scaled.fill(0)  # Reset the scaled array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58acc1e-8120-4045-81d4-74ebe1ed4994",
   "metadata": {},
   "source": [
    "## Test data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd03a07-af09-4c6a-88f1-f5699686f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image_into_tiles(image, tile_size):    \n",
    "    #Splits an image into tiles of specified size.\n",
    "    \n",
    "    tiles = []\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    for y in range(0, height, tile_size):\n",
    "        for x in range(0, width, tile_size):\n",
    "            tile = image[y:y + tile_size, x:x + tile_size]\n",
    "            # Check if the tile is the right size (to avoid edge tiles)\n",
    "            if tile.shape[0] == tile_size and tile.shape[1] == tile_size:\n",
    "                tiles.append(tile)\n",
    "    \n",
    "    return tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44e7b8-a951-4010-b3f5-16e8f6f5baba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_overlapping_patches(image, patch_size, overlap):\n",
    "    img_array = np.array(image)\n",
    "    patches = []\n",
    "    coords = []\n",
    "\n",
    "    step = patch_size - overlap\n",
    "    height, width = img_array.shape[:2]\n",
    "    \n",
    "    for y in range(0, height - patch_size + 1, step):\n",
    "        for x in range(0, width - patch_size + 1, step):\n",
    "            patch = img_array[y:y + patch_size, x:x + patch_size]\n",
    "            coords.append((x,y))\n",
    "            patches.append(patch)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e591487-f2c2-4c0b-ad74-d6b284004026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_in_folder(folder_path, tile_size, tag):\n",
    "    #Processes all images in the specified folder, splitting them into tiles.\n",
    "    \n",
    "    # Create output folder for tiles\n",
    "    output_folder = Path(folder_path)\n",
    "    output_folder = os.path.join(output_folder.parent.absolute(),'noisy_tiles')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for i,filename in enumerate(os.listdir(folder_path)):\n",
    "        if filename.lower().endswith('.png'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is None:\n",
    "                print(f\"Unable to read image: {image_path}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"Processing image({i}) {filename}\")\n",
    "            #tiles = split_image_into_tiles(image, tile_size)\n",
    "            tiles = create_overlapping_patches(image, tile_size, 128)\n",
    "            \n",
    "            # Save each tile\n",
    "            for k, tile in enumerate(tiles):\n",
    "                tile_filename = f\"{os.path.splitext(filename)[0]}{tag}_tile_{k}.png\"\n",
    "                tile_path = os.path.join(output_folder, tile_filename)\n",
    "                cv2.imwrite(tile_path, tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0454a38-3b3f-4884-9fbf-f036826ca7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder path to FMD testset and the tile size\n",
    "tile_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d75645-6534-4e2e-8309-9b0d8b60fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images of various noise levels in FMD folder\n",
    "noise_levels = ['raw','avg2','avg4','avg8','avg16']\n",
    "for i, levels in enumerate(noise_levels):\n",
    "    print(f'working on {levels} images')\n",
    "    process_images_in_folder(FMD_testmix/levels,tile_size,levels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
