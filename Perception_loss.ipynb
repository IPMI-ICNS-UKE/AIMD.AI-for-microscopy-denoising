{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a08f5141-b6d3-4679-be2e-8d0b5b1334f8",
   "metadata": {},
   "source": [
    "## Perception loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "529f3d7b-09c2-467f-b2ef-108e9b2fb828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.15'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "from torcheval.metrics.functional import peak_signal_noise_ratio\n",
    "import fastai; fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f785f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define gram matrix calculation which enables the use of gram (style) loss\n",
    "def gram_matrix(x):\n",
    "    n,c,h,w = x.size()\n",
    "    x = x.view(n, c, -1)\n",
    "    return (x @ x.transpose(1,2))/(c*h*w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e2ce324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set VGG16 model for inference during loss calculation\n",
    "vgg_m = vgg16_bn(True).features.eval()\n",
    "vgg_m = vgg_m.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffa092f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5, 12, 22, 32, 42],\n",
       " [ReLU(inplace=True),\n",
       "  ReLU(inplace=True),\n",
       "  ReLU(inplace=True),\n",
       "  ReLU(inplace=True),\n",
       "  ReLU(inplace=True)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check which blocks are MaxPool layers -> enables grabbing feature maps prior to dimension reduction\n",
    "blocks = [i-1 for i,o in enumerate(vgg_m.children()) if isinstance(o,nn.MaxPool2d)]\n",
    "blocks, [vgg_m[i] for i in blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7adeb-73d4-4bdd-a927-6650ee630ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyper parameters for model and loss\n",
    "wd, y_range, base_loss, ref_loss, bbone = 1e-3, (-3, 3), F.l1_loss, F.mse_loss, resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c41789eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature loss class with weighting factors for feature and gram contributions\n",
    "class FeatureLoss(Module):\n",
    "    def __init__(self, m_feat, layer_ids, L1_wgt, feature_wgts, gram_wgts):\n",
    "        self.m_feat = m_feat\n",
    "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
    "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
    "        self.feature_wgts = feature_wgts\n",
    "        self.gram_wgts = gram_wgts\n",
    "        self.L1_wgt = L1_wgt\n",
    "        self.metric_names = ['MSE',] +['PSNR',] +['l1',] +[f'feat_{i}' for i in range(len(layer_ids))\n",
    "        ] + [f'gram_{i}' for i in range(len(layer_ids))]         \n",
    "                            \n",
    "    # feature generator\n",
    "    def make_features(self, x, clone=False):\n",
    "        self.m_feat(x)\n",
    "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "    \n",
    "    def forward(self, input, target, reduction='mean'):\n",
    "        out_feat = self.make_features(target, clone=True)\n",
    "        in_feat = self.make_features(input)\n",
    "        self.feat_losses = [ref_loss(input,target,reduction=reduction)]                     # MSE as metric\n",
    "        self.feat_losses += [peak_signal_noise_ratio(input,target)]                         # PSNR as metric\n",
    "        self.feat_losses += [base_loss(input,target,reduction=reduction)]                   # F1 loss \n",
    "        self.feat_losses += [base_loss(f_in, f_out,reduction=reduction)*w                   # Feature loss \n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.feature_wgts)]\n",
    "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out),reduction=reduction)*w*20000    # gram loss\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.gram_wgts)]\n",
    "        if reduction=='none':\n",
    "            self.feat_losses = [f.mean(dim=[1,2,3]) for f in self.feat_losses[:4]] + [f.mean(dim=[1,2]) for f in self.feat_losses[4:]]\n",
    "        for n,l in zip(self.metric_names, self.feat_losses): setattr(self, n, l)\n",
    "        return sum(self.feat_losses[2:])           # 2: to exclude MSE and PSNR from loss calculation, but to have them as metrics\n",
    "\n",
    "    def __del__(self): self.hooks.remove()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
