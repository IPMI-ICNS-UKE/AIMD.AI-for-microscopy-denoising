{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a08f5141-b6d3-4679-be2e-8d0b5b1334f8",
   "metadata": {},
   "source": [
    "__Inference set up - Basemodel_FMD__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "529f3d7b-09c2-467f-b2ef-108e9b2fb828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.15'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "import os\n",
    "import pathlib\n",
    "import fastai; fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "425de756-b3ed-4074-9541-09e1826bd0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a26f1fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'NVIDIA GeForce RTX 4060 Ti')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device(), torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f652f4-dc36-49dc-8286-c78980c39e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a99af86-7f4e-4d4a-bb43-525d55e91992",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab85961-435e-4423-aa0d-05e93263049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_GT = path/'Daten/FMD_GT'\n",
    "path_noisy = path/'Daten/FMD_noisy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd82cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "227497ed-5c71-4a29-af68-b63e4a0d8d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/mambaforge/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/david/mambaforge/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "%run Dataloader_FMD.ipynb\n",
    "%run Perception_loss.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "769fce40-7105-41e0-a7f2-4b1d457c2092",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_den = get_dls(38, 256)  # required to generate learner       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56a3c67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = FeatureLoss(vgg_m, blocks[2:5],[1], [1,1,1], [1,1,1]) # dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac7d5e3a-60e0-433f-8b31-b9c9efadea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define learner w/o learning parameters (e.g. metrics, cbs)\n",
    "def create_gen_learner():\n",
    "    return unet_learner(dls_den, bbone, loss_func=loss_func, blur=True, norm_type=NormType.Weight, \n",
    "                        self_attention=True, y_range=y_range\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e63f025e-64bd-4189-b367-262f1e2d6ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/mambaforge/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Learner.to_fp16 of <fastai.learner.Learner object at 0x7c9950d112a0>>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create learner\n",
    "learn_den = create_gen_learner()\n",
    "# load the Basemodel into that leaner and convert to fp16\n",
    "learn_den.load('Basemodel_FMD').to_fp16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802bef0d-892f-449e-a7a8-9ecd8008bce5",
   "metadata": {},
   "source": [
    "__Set up data and perform inference__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "788965f1-502e-4510-aa30-31a0f1eb50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = path/'Daten/FMD_testmix/noisy_tiles'\n",
    "path_preds = path/'Daten/FMD_testmix/FMD_pred_tiles'\n",
    "path_preds.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3337f32a-7231-431b-a18a-e1ae1856f66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Path('/home/david/mnt_anarchyNAS/lohrd/Github/AIMD/Daten/FMD_testmix/noisy_tiles/WideField_BPAE_G_1avg16_tile_2.png'),\n",
       " 960)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check path\n",
    "test_files = get_image_files(path_test)\n",
    "test_files[0], len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9f67aeb-0dfc-4f97-8b5d-a1c8e5b91e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test set dataloader\n",
    "test_dl = learn_den.dls.test_dl(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d00aaec-1580-4faf-910a-26dccd860f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions, decode oop over all predictions and save them as 8 bit png\n",
    "def save_preds(dl, learn):\n",
    "  \"Save away predictions\"\n",
    "  names = dl.dataset.items\n",
    "  \n",
    "  inp, preds, _,decoded = learn.get_preds(dl=dl, with_input=True, with_decoded=True)\n",
    "  for i,pred in enumerate(preds):\n",
    "      dec = dl.after_batch.decode((TensorImage(pred[None]),))[0][0]\n",
    "      arr = dec.numpy().transpose(1,2,0).astype(np.uint8)\n",
    "      Image.fromarray(arr[:,:,0]).save(path_preds/names[i].name)\n",
    "  return inp, preds, decoded       # return outputs for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7b501a2-93eb-4815-8a6e-46e9f97ceac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/mambaforge/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1716905971132/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:84.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "inp, preds, dec = save_preds(test_dl, learn_den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb119f20-be1f-4dc2-8ead-4a875273cd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nchunk_size = 5000\\nfor k in range(0,len(test_files),chunk_size):\\n    chunk = test_files[k:k+chunk_size]\\n    test_dl=learn_den.dls.test_dl(chunk)\\n    inp, preds, dec = save_preds(test_dl, learn_den)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use this loop with a chunksize that works for your RAM, if your RAM cant contain all predictions simultaneously\n",
    "\"\"\"\n",
    "chunk_size = 5000\n",
    "for k in range(0,len(test_files),chunk_size):\n",
    "    chunk = test_files[k:k+chunk_size]\n",
    "    test_dl=learn_den.dls.test_dl(chunk)\n",
    "    inp, preds, dec = save_preds(test_dl, learn_den)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
